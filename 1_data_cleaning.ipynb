{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.5 64-bit ('env': venv)"
  },
  "interpreter": {
   "hash": "ff8668b9c2b2d1baaf1a01ba69b056e3b7375889890260109335ff682838045a"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# 1.1 Imports"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from pyspark.sql import SparkSession, Window\n",
    "from pyspark import SparkFiles\n",
    "from pyspark.sql.functions import avg, col, concat, count, desc, \\\n",
    "asc, explode, lit, min, max, split, stddev, udf, isnan, when, rank, \\\n",
    "log, sqrt, cbrt, exp, round\n",
    "from pyspark.sql.functions import sum as Fsum\n",
    "from pyspark.sql.types import IntegerType\n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import LogisticRegression, \\\n",
    "LogisticRegressionModel, RandomForestClassifier, \\\n",
    "RandomForestClassificationModel, GBTClassifier, \\\n",
    "GBTClassificationModel\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "\n",
    "from pyspark.ml.feature import CountVectorizer, IDF, Normalizer, \\\n",
    "PCA, RegexTokenizer, Tokenizer, StandardScaler, StopWordsRemover, \\\n",
    "StringIndexer, VectorAssembler, MaxAbsScaler\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.clustering import KMeans\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "21/07/16 16:51:27 WARN Utils: Your hostname, Yats-MacBook-Pro.local resolves to a loopback address: 127.0.0.1; using 10.192.149.232 instead (on interface en0)\n",
      "21/07/16 16:51:27 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/Users/abrahamleung/Documents/GitHub/Sparkify-User-Churn-Prediction/env/lib/python3.9/site-packages/pyspark/jars/spark-unsafe_2.12-3.1.2.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "21/07/16 16:51:27 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "# create parksession\n",
    "\n",
    "spark = SparkSession.builder.master('local') \\\n",
    "        .appName('Sparkify').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Row(artist='Martha Tilston', auth='Logged In', firstName='Colin', gender='M', itemInSession=50, lastName='Freeman', length=277.89016, level='paid', location='Bakersfield, CA', method='PUT', page='NextSong', registration=1538173362000, sessionId=29, song='Rockpools', status=200, ts=1538352117000, userAgent='Mozilla/5.0 (Windows NT 6.1; WOW64; rv:31.0) Gecko/20100101 Firefox/31.0', userId='30')"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "# load data\n",
    "\n",
    "path = 'mini_sparkify_event_data.json'\n",
    "df = spark.read.json(path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "root\n |-- artist: string (nullable = true)\n |-- auth: string (nullable = true)\n |-- firstName: string (nullable = true)\n |-- gender: string (nullable = true)\n |-- itemInSession: long (nullable = true)\n |-- lastName: string (nullable = true)\n |-- length: double (nullable = true)\n |-- level: string (nullable = true)\n |-- location: string (nullable = true)\n |-- method: string (nullable = true)\n |-- page: string (nullable = true)\n |-- registration: long (nullable = true)\n |-- sessionId: long (nullable = true)\n |-- song: string (nullable = true)\n |-- status: long (nullable = true)\n |-- ts: long (nullable = true)\n |-- userAgent: string (nullable = true)\n |-- userId: string (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "# check schema\n",
    "df.printSchema()"
   ]
  },
  {
   "source": [
    "# 1.2 Missing Values"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# 1.2.1 Observations"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "total number of rows: 286500\n"
     ]
    }
   ],
   "source": [
    "# total number of rows\n",
    "print(f'total number of rows: {df.count()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "+-----------------------------------------------+\n",
      "|count(CASE WHEN (artist IS NULL) THEN true END)|\n",
      "+-----------------------------------------------+\n",
      "|                                          58392|\n",
      "+-----------------------------------------------+\n",
      "\n",
      "+---------------------------------------------+\n",
      "|count(CASE WHEN (auth IS NULL) THEN true END)|\n",
      "+---------------------------------------------+\n",
      "|                                            0|\n",
      "+---------------------------------------------+\n",
      "\n",
      "+--------------------------------------------------+\n",
      "|count(CASE WHEN (firstName IS NULL) THEN true END)|\n",
      "+--------------------------------------------------+\n",
      "|                                              8346|\n",
      "+--------------------------------------------------+\n",
      "\n",
      "+-----------------------------------------------+\n",
      "|count(CASE WHEN (gender IS NULL) THEN true END)|\n",
      "+-----------------------------------------------+\n",
      "|                                           8346|\n",
      "+-----------------------------------------------+\n",
      "\n",
      "+------------------------------------------------------+\n",
      "|count(CASE WHEN (itemInSession IS NULL) THEN true END)|\n",
      "+------------------------------------------------------+\n",
      "|                                                     0|\n",
      "+------------------------------------------------------+\n",
      "\n",
      "+-------------------------------------------------+\n",
      "|count(CASE WHEN (lastName IS NULL) THEN true END)|\n",
      "+-------------------------------------------------+\n",
      "|                                             8346|\n",
      "+-------------------------------------------------+\n",
      "\n",
      "+-----------------------------------------------+\n",
      "|count(CASE WHEN (length IS NULL) THEN true END)|\n",
      "+-----------------------------------------------+\n",
      "|                                          58392|\n",
      "+-----------------------------------------------+\n",
      "\n",
      "+----------------------------------------------+\n",
      "|count(CASE WHEN (level IS NULL) THEN true END)|\n",
      "+----------------------------------------------+\n",
      "|                                             0|\n",
      "+----------------------------------------------+\n",
      "\n",
      "+-------------------------------------------------+\n",
      "|count(CASE WHEN (location IS NULL) THEN true END)|\n",
      "+-------------------------------------------------+\n",
      "|                                             8346|\n",
      "+-------------------------------------------------+\n",
      "\n",
      "+-----------------------------------------------+\n",
      "|count(CASE WHEN (method IS NULL) THEN true END)|\n",
      "+-----------------------------------------------+\n",
      "|                                              0|\n",
      "+-----------------------------------------------+\n",
      "\n",
      "+---------------------------------------------+\n",
      "|count(CASE WHEN (page IS NULL) THEN true END)|\n",
      "+---------------------------------------------+\n",
      "|                                            0|\n",
      "+---------------------------------------------+\n",
      "\n",
      "+-----------------------------------------------------+\n",
      "|count(CASE WHEN (registration IS NULL) THEN true END)|\n",
      "+-----------------------------------------------------+\n",
      "|                                                 8346|\n",
      "+-----------------------------------------------------+\n",
      "\n",
      "+--------------------------------------------------+\n",
      "|count(CASE WHEN (sessionId IS NULL) THEN true END)|\n",
      "+--------------------------------------------------+\n",
      "|                                                 0|\n",
      "+--------------------------------------------------+\n",
      "\n",
      "+---------------------------------------------+\n",
      "|count(CASE WHEN (song IS NULL) THEN true END)|\n",
      "+---------------------------------------------+\n",
      "|                                        58392|\n",
      "+---------------------------------------------+\n",
      "\n",
      "+-----------------------------------------------+\n",
      "|count(CASE WHEN (status IS NULL) THEN true END)|\n",
      "+-----------------------------------------------+\n",
      "|                                              0|\n",
      "+-----------------------------------------------+\n",
      "\n",
      "+-------------------------------------------+\n",
      "|count(CASE WHEN (ts IS NULL) THEN true END)|\n",
      "+-------------------------------------------+\n",
      "|                                          0|\n",
      "+-------------------------------------------+\n",
      "\n",
      "+--------------------------------------------------+\n",
      "|count(CASE WHEN (userAgent IS NULL) THEN true END)|\n",
      "+--------------------------------------------------+\n",
      "|                                              8346|\n",
      "+--------------------------------------------------+\n",
      "\n",
      "+-----------------------------------------------+\n",
      "|count(CASE WHEN (userId IS NULL) THEN true END)|\n",
      "+-----------------------------------------------+\n",
      "|                                              0|\n",
      "+-----------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# number of missing values\n",
    "\n",
    "for c in df.columns:\n",
    "    df.select(\n",
    "        [count(when(df[c].isNull(),True))]\n",
    "    ).show()"
   ]
  },
  {
   "source": [
    "# 1.2.2 Missing Values in userId"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "+------+\n",
      "|userId|\n",
      "+------+\n",
      "|      |\n",
      "|    10|\n",
      "|   100|\n",
      "|100001|\n",
      "|100002|\n",
      "|100003|\n",
      "|100004|\n",
      "|100005|\n",
      "|100006|\n",
      "|100007|\n",
      "+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# from above findings, 0 rows in userId is NULL\n",
    "# so we check for samples\n",
    "\n",
    "df.select(['userId']).drop_duplicates().orderBy(df['userId']).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the first row is an empty string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a temporary view for running SQL queries\n",
    "df.createOrReplaceTempView('df_table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+-------------------+\n|               page|\n+-------------------+\n|               Home|\n|              About|\n|Submit Registration|\n|              Login|\n|           Register|\n|               Help|\n|              Error|\n+-------------------+\n\n"
     ]
    }
   ],
   "source": [
    "# display the page events of the user with empty string userId\n",
    "\n",
    "spark.sql(\n",
    "    '''\n",
    "    SELECT DISTINCT page\n",
    "    FROM df_table\n",
    "    WHERE userId == ''\n",
    "    '''\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "+--------------------+\n",
      "|                page|\n",
      "+--------------------+\n",
      "|              Cancel|\n",
      "|         Thumbs Down|\n",
      "|                Home|\n",
      "|         Roll Advert|\n",
      "|              Logout|\n",
      "|Cancellation Conf...|\n",
      "|            Settings|\n",
      "|     Add to Playlist|\n",
      "|          Add Friend|\n",
      "|            NextSong|\n",
      "|           Thumbs Up|\n",
      "|                Help|\n",
      "|             Upgrade|\n",
      "|               Error|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# display the page events of another user with non-empty string userId\n",
    "\n",
    "spark.sql(\n",
    "    '''\n",
    "    SELECT DISTINCT page\n",
    "    FROM df_table\n",
    "    WHERE userId == 100001\n",
    "    '''\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can see that \n",
    "# the page events of empty string userId user has nearly no features page except\n",
    "# 'Submit Registration' which might indicate that it is a user with incomplete registration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the row with empty userId\n",
    "df = df.filter(df['userId'] != '')"
   ]
  },
  {
   "source": [
    "# 1.3 Exploratory Data Analysis (EDA)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# 1.3.1 Overview of Numerical Features"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numerical columns\n",
    "num_cols = ['itemInSession', 'registration', 'status', 'ts', 'length']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "+-------+------------------+--------------------+------------------+--------------------+-----------------+\n",
      "|summary|     itemInSession|        registration|            status|                  ts|           length|\n",
      "+-------+------------------+--------------------+------------------+--------------------+-----------------+\n",
      "|  count|            278154|              278154|            278154|              278154|           228108|\n",
      "|   mean|114.89918174824018|1.535358834084427...|209.10321620397335|1.540958915431871...|249.1171819778458|\n",
      "| stddev|  129.851729399489| 3.291321616327586E9|30.151388851328214|1.5068287123306298E9|99.23517921058361|\n",
      "|    min|                 0|       1521380675000|               200|       1538352117000|          0.78322|\n",
      "|    max|              1321|       1543247354000|               404|       1543799476000|       3024.66567|\n",
      "+-------+------------------+--------------------+------------------+--------------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# describe numerical columns\n",
    "df.select(num_cols).describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "+------+------+-----+\n",
      "|status| count|    %|\n",
      "+------+------+-----+\n",
      "|   200|254718|91.57|\n",
      "|   307| 23184| 8.33|\n",
      "|   404|   252| 0.09|\n",
      "+------+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 'status' is HTTP status\n",
    "\n",
    "header = 'status'\n",
    "df.groupBy(header).count() \\\n",
    ".withColumn('%', round((col('count')/df.count())*100,2)) \\\n",
    ".orderBy('%', ascending=False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'status' should be classified as categorical feature"
   ]
  },
  {
   "source": [
    "# 1.3.2 Overview of Categorical Features"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# catagorical columns\n",
    "cat_cols = [\n",
    "    'artist', 'auth', 'firstName', 'lastName', \n",
    "    'gender', 'level', 'location','method', \n",
    "    'page', 'song', 'userAgent'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we only observe the features that can be classified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "+---------+------+-----+\n",
      "|     auth| count|    %|\n",
      "+---------+------+-----+\n",
      "|Logged In|278102|99.98|\n",
      "|Cancelled|    52| 0.02|\n",
      "+---------+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# values count of 'auth'\n",
    "\n",
    "header = 'auth'\n",
    "df.groupBy(header).count() \\\n",
    ".withColumn('%', round((col('count')/df.count())*100,2)) \\\n",
    ".orderBy('%', ascending=False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "+------+------+-----+\n",
      "|gender| count|    %|\n",
      "+------+------+-----+\n",
      "|     F|154578|55.57|\n",
      "|     M|123576|44.43|\n",
      "+------+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# values count of 'gender'\n",
    "\n",
    "header = 'gender'\n",
    "df.groupBy(header).count() \\\n",
    ".withColumn('%', round((col('count')/df.count())*100,2)) \\\n",
    ".orderBy('%', ascending=False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "+-----+------+-----+\n",
      "|level| count|    %|\n",
      "+-----+------+-----+\n",
      "| paid|222433|79.97|\n",
      "| free| 55721|20.03|\n",
      "+-----+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# values count of 'level'\n",
    "\n",
    "header = 'level'\n",
    "df.groupBy(header).count() \\\n",
    ".withColumn('%', round((col('count')/df.count())*100,2)) \\\n",
    ".orderBy('%', ascending=False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "+--------------------+-----+-----+\n",
      "|            location|count|    %|\n",
      "+--------------------+-----+-----+\n",
      "|Los Angeles-Long ...|30131|10.83|\n",
      "|New York-Newark-J...|23684| 8.51|\n",
      "|Boston-Cambridge-...|13873| 4.99|\n",
      "|Houston-The Woodl...| 9499| 3.42|\n",
      "|Charlotte-Concord...| 7780|  2.8|\n",
      "+--------------------+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# first 5 values count of 'location'\n",
    "\n",
    "header = 'location'\n",
    "df.groupBy(header).count() \\\n",
    ".withColumn('%', round((col('count')/df.count())*100,2)) \\\n",
    ".orderBy('%', ascending=False).limit(5).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "+------+------+-----+\n",
      "|method| count|    %|\n",
      "+------+------+-----+\n",
      "|   PUT|257818|92.69|\n",
      "|   GET| 20336| 7.31|\n",
      "+------+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# values count of 'method'\n",
    "\n",
    "header = 'method'\n",
    "df.groupBy(header).count() \\\n",
    ".withColumn('%', round((col('count')/df.count())*100,2)) \\\n",
    ".orderBy('%', ascending=False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "['Cancel', 'Submit Downgrade', 'Thumbs Down', 'Home', 'Downgrade', 'Roll Advert', 'Logout', 'Save Settings', 'Cancellation Confirmation', 'About', 'Settings', 'Add to Playlist', 'Add Friend', 'NextSong', 'Thumbs Up', 'Help', 'Upgrade', 'Error', 'Submit Upgrade']\n"
     ]
    }
   ],
   "source": [
    "# unique values of 'page'\n",
    "\n",
    "header = 'page'\n",
    "print([x[header] for x in df.select(header).drop_duplicates().collect()])"
   ]
  },
  {
   "source": [
    "# 1.3.3 Define Churn"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# churn can be detected by the appearance of 'Cancellation Confirmation' in column 'page'\n",
    "\n",
    "# udf? lambda? map?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# END"
   ]
  }
 ]
}